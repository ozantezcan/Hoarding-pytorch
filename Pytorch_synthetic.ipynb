{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## Synthetic DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Transfer Learning tutorial\n",
    "==========================\n",
    "**Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`_\n",
    "\n",
    "In this tutorial, you will learn how to train your network using\n",
    "transfer learning. You can read more about the transfer learning at `cs231n\n",
    "notes <http://cs231n.github.io/transfer-learning/>`__\n",
    "\n",
    "Quoting this notes,\n",
    "\n",
    "    In practice, very few people train an entire Convolutional Network\n",
    "    from scratch (with random initialization), because it is relatively\n",
    "    rare to have a dataset of sufficient size. Instead, it is common to\n",
    "    pretrain a ConvNet on a very large dataset (e.g. ImageNet, which\n",
    "    contains 1.2 million images with 1000 categories), and then use the\n",
    "    ConvNet either as an initialization or a fixed feature extractor for\n",
    "    the task of interest.\n",
    "\n",
    "These two major transfer learning scenarios looks as follows:\n",
    "\n",
    "-  **Finetuning the convnet**: Instead of random initializaion, we\n",
    "   initialize the network with a pretrained network, like the one that is\n",
    "   trained on imagenet 1000 dataset. Rest of the training looks as\n",
    "   usual.\n",
    "-  **ConvNet as fixed feature extractor**: Here, we will freeze the weights\n",
    "   for all of the network except that of the final fully connected\n",
    "   layer. This last fully connected layer is replaced with a new one\n",
    "   with random weights and only this layer is trained.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchsample-0.1.2-py3.6.egg/torchsample/datasets.py:16: UserWarning: Cant import nibabel.. Cant load brain images\n"
     ]
    }
   ],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "We will use torchvision and torch.utils.data packages for loading the\n",
    "data.\n",
    "\n",
    "The problem we're going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
    "There are 75 validation images for each class. Usually, this is a very\n",
    "small dataset to generalize upon, if trained from scratch. Since we\n",
    "are using transfer learning, we should be able to generalize reasonably\n",
    "well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n",
    "\n",
    ".. Note ::\n",
    "   Download the data from\n",
    "   `here <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_\n",
    "   and extract it to the current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BasicHouse_2017-07-01-rated', 'BriansHouse_2017-06-30-rated', 'RuralHome_2017-06-30-rated', 'SmallApt_2017-06-29-rated']\n",
      "768\n",
      "768\n",
      "329\n",
      "329\n",
      "[12.59016393442623, 7.757575757575758, 10.816901408450704, 13.963636363636363, 8.629213483146067, 7.603960396039604, 5.605839416058394, 8.533333333333333, 11.815384615384616]\n",
      "['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training \n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        #ts_transforms.RandomRotate(30)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "'''\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        ts_transforms.TypeCast('float'), \n",
    "        #ts_transforms.ChannelsFirst(),\n",
    "        ts_transforms.RangeNorm(0,1),\n",
    "        ts_transforms.RandomRotate(30),\n",
    "        ts_transforms.RandomGamma(.2,1.8),\n",
    "        ts_transforms.RandomSaturation(.5,.9),\n",
    "        ts_transforms.RandomBrightness(-.2,.2)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        ts_transforms.TypeCast('float'), \n",
    "        #ts_transforms.ChannelsFirst(),\n",
    "        ts_transforms.RangeNorm(0,1)\n",
    "    ]),\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "rootdir='//media//mtezcan//New Volume/HoardingImages//_rated//'\n",
    "valdir='//media//mtezcan//New Volume/HoardingImages//_val//House//BR'\n",
    "subdirs=os.listdir(rootdir)\n",
    "print(subdirs)\n",
    "roomdirs=['//BR','//Kitchen','//LR']\n",
    "data_dir = '..//Data_Sets//pruned//good'\n",
    "dsets = {x: datasets.ImageFolder_mtezcan([os.path.join(data_dir, x)], data_transforms[x])\n",
    "         for x in ['train', 'val']}\n",
    "\n",
    "#dsets = {'train':datasets.ImageFolder_mtezcan([rootdir+subdir+room for subdir in subdirs\n",
    "#                                               for room in roomdirs], data_transforms['train']),\n",
    "#         'val':datasets.ImageFolder_mtezcan([valdir], data_transforms['val'])}\n",
    " \n",
    "\n",
    "weights,wpc = ft.make_weights_for_balanced_classes(dsets['train'].imgs, len(dsets['train'].classes))  \n",
    "print(wpc)\n",
    "weights = torch.DoubleTensor(weights) \n",
    "#sampler = {'train':torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)) ,\n",
    "sampler = {'train':None,\n",
    "           'val':None}\n",
    "shuffler={'train':True,'val':False}\n",
<<<<<<< HEAD
    "dset_loaders = {x:torch.utils.data.DataLoader(dsets[x], batch_size=32,shuffle=shuffler[x],sampler=sampler[x], num_workers=4)\n",
=======
    "dset_loaders = {x:torch.utils.data.DataLoader(dsets[x], batch_size=4,shuffle=shuffler[x],sampler=sampler[x], num_workers=4)\n",
>>>>>>> 7bc07c3e444b6249af57f138626e96d4fa2e9284
    "                for x in ['train','val']}\n",
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "dset_classes = dsets['train'].classes\n",
    "print(dset_classes)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "#use_gpu=False\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "inputs, classes = next(iter(dset_loaders['train']))\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs,nrow=4)\n",
    "print('Size of the input tensors in one batch after grid is  '+str(out.size()))\n",
    "ft.imshow(out, title=[dset_classes[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the convnet\n",
    "----------------------\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TO-BE-DELETED\n",
    "train = []\n",
    "labels = []\n",
    "for i in range(100):\n",
    "    category = (np.random.choice([0, 1]), np.random.choice([0, 1]))\n",
    "    if category == (1, 0):\n",
    "        train.append([np.random.uniform(0.1, 1), 0])\n",
    "        labels.append([1, 0, 1])\n",
    "    if category == (0, 1):\n",
    "        train.append([0, np.random.uniform(0.1, 1)])\n",
    "        labels.append([0, 1, 0])\n",
    "    if category == (0, 0):\n",
    "        train.append([np.random.uniform(0.1, 1), np.random.uniform(0.1, 1)])\n",
    "        labels.append([0, 0, 1])\n",
    "        \n",
    "\n",
    "\n",
    "inputs, label = next(iter(dset_loaders['train']))\n",
    "labels=[]\n",
    "print(label)\n",
    "for lbl in label:\n",
    "    x=np.zeros(11)\n",
    "    x[lbl:lbl+3]=1\n",
    "    x=x[1:-1]\n",
    "    labels.append(x)\n",
    "print(labels)\n",
    "    \n",
    "i=0\n",
    "labelsv = Variable(torch.FloatTensor(labels).cuda()).view(-1, 9)\n",
    "print(labelsv)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 17,
>>>>>>> 7bc07c3e444b6249af57f138626e96d4fa2e9284
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the fine tune layer is 512\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "#model_ft=torch.load('./saved_models/resnet_synthetic_7_8_17.mdl')\n",
    "#print('The CNN model is')\n",
    "#print(model_ft)\n",
    "#print(list(model_ft.children())[:-1])\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "#setattr(model_ft.classifier, '6', nn.Linear(num_ftrs, 9))\n",
    "model_ft.fc = nn.Linear(num_ftrs, 9)\n",
    "#print(model_ft)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
<<<<<<< HEAD
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
=======
    "\n",
>>>>>>> 7bc07c3e444b6249af57f138626e96d4fa2e9284
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in the fine tune layer is 1000\n",
      "AlexNet (\n",
      "  (features): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU (inplace)\n",
      "    (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU (inplace)\n",
      "    (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU (inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU (inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU (inplace)\n",
      "    (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential (\n",
      "    (0): Dropout (p = 0.5)\n",
      "    (1): Linear (9216 -> 4096)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Dropout (p = 0.5)\n",
      "    (4): Linear (4096 -> 4096)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (4096 -> 1000)\n",
      "    (7): ReLU (inplace)\n",
      "    (8): Dropout (p = 0.5)\n",
      "    (9): Linear (1000 -> 9)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.alexnet(pretrained=True)\n",
    "\n",
    "#print('The CNN model is')\n",
    "\n",
    "#print(list(model_ft.children())[:-1])\n",
    "num_ftrs = model_ft.classifier[6].out_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "setattr(model_ft.classifier, '7', nn.ReLU(inplace=True))\n",
    "setattr(model_ft.classifier, '8', nn.Dropout())\n",
    "setattr(model_ft.classifier, '9', nn.Linear(num_ftrs,9))\n",
    "print(model_ft)\n",
    "#model_ft.fc = nn.Linear(num_ftrs, 9)\n",
    "#print(model_ft)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
<<<<<<< HEAD
    "#optimizer_ft = optim.Adam(model_ft.parameters())\n",
=======
    "# Observe that all parameters are being optimized\n",
>>>>>>> 7bc07c3e444b6249af57f138626e96d4fa2e9284
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 18,
>>>>>>> 7bc07c3e444b6249af57f138626e96d4fa2e9284
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 0/99\n",
      "----------\n",
      "LR is set to 0.001\n",
      "train Loss: 0.0046 Acc: 0.5286 CIR-1: 0.9935\n",
      "val Loss: 0.0126 Acc: 0.3435 CIR-1: 0.8663\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1265:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 108, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 42, in default_loader\n",
      "    return Image.open(path).convert('RGB')\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 946, in convert\n",
      "    im = self.im.convert(mode, dither)\n",
      "KeyboardInterrupt\n",
      "Process Process-1266:\n",
      "Process Process-1267:\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-48fb440131cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m model_ft = ft.train_model(model_ft, criterion, optimizer_ft,dset_loaders,dset_sizes,writer,\n\u001b[1;32m      7\u001b[0m                         \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                          lr_scheduler=ft.exp_lr_scheduler)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#model_ft = ft.train_model(model_ft, criterion, optimizer_ft,dset_loaders,dset_sizes,writer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/Documents/Hoarding/Notebook/functions/fine_tune.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dset_loaders, dset_sizes, writer, lr_scheduler, use_gpu, num_epochs, batch_size, num_log, init_lr)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 237\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     38\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     39\u001b[0m                _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 108, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 42, in default_loader\n",
      "    return Image.open(path).convert('RGB')\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 857, in convert\n",
      "    self.load()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 234, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 108, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 42, in default_loader\n",
      "    return Image.open(path).convert('RGB')\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 857, in convert\n",
      "    self.load()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 234, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "Process Process-1268:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 41, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 110, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/transforms.py\", line 29, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchvision/transforms.py\", line 140, in __call__\n",
      "    return img.resize((ow, oh), self.interpolation)\n",
      "  File \"/home/mtezcan/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1645, in resize\n",
      "    return self._new(self.im.resize(size, resample))\n",
      "KeyboardInterrupt\n"
=======
      "Epoch 0/49\n",
      "----------\n",
      "LR is set to 0.001\n",
      "train Loss: 0.1448 Acc: 0.2018 CIR-1: 0.5312\n",
      "val Loss: 0.1223 Acc: 0.2827 CIR-1: 0.7143\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.1242 Acc: 0.2422 CIR-1: 0.6576\n",
      "val Loss: 0.1127 Acc: 0.2766 CIR-1: 0.6960\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.2578 CIR-1: 0.7122\n",
      "val Loss: 0.1047 Acc: 0.3283 CIR-1: 0.7599\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.1139 Acc: 0.2617 CIR-1: 0.7044\n",
      "val Loss: 0.1035 Acc: 0.3343 CIR-1: 0.7599\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.1061 Acc: 0.3021 CIR-1: 0.7565\n",
      "val Loss: 0.1002 Acc: 0.3374 CIR-1: 0.7842\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.1022 Acc: 0.3125 CIR-1: 0.7917\n",
      "val Loss: 0.0964 Acc: 0.3951 CIR-1: 0.8207\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.0983 Acc: 0.2956 CIR-1: 0.7904\n",
      "val Loss: 0.0952 Acc: 0.3678 CIR-1: 0.8328\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "LR is set to 0.0001\n",
      "train Loss: 0.0936 Acc: 0.3398 CIR-1: 0.8503\n",
      "val Loss: 0.0953 Acc: 0.3799 CIR-1: 0.8237\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0939 Acc: 0.3490 CIR-1: 0.8372\n",
      "val Loss: 0.0962 Acc: 0.3830 CIR-1: 0.8298\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0915 Acc: 0.3503 CIR-1: 0.8372\n",
      "val Loss: 0.0934 Acc: 0.3587 CIR-1: 0.8389\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0946 Acc: 0.3398 CIR-1: 0.8203\n",
      "val Loss: 0.0936 Acc: 0.3617 CIR-1: 0.8237\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0969 Acc: 0.3398 CIR-1: 0.8333\n",
      "val Loss: 0.0928 Acc: 0.3617 CIR-1: 0.8298\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.3516 CIR-1: 0.8346\n",
      "val Loss: 0.0953 Acc: 0.3739 CIR-1: 0.8298\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0924 Acc: 0.3385 CIR-1: 0.8242\n",
      "val Loss: 0.0928 Acc: 0.3739 CIR-1: 0.8328\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "LR is set to 1.0000000000000003e-05\n",
      "train Loss: 0.0928 Acc: 0.3633 CIR-1: 0.8490\n",
      "val Loss: 0.0919 Acc: 0.3587 CIR-1: 0.8389\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0888 Acc: 0.3477 CIR-1: 0.8477\n",
      "val Loss: 0.0926 Acc: 0.3708 CIR-1: 0.8359\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0899 Acc: 0.3451 CIR-1: 0.8568\n",
      "val Loss: 0.0928 Acc: 0.3921 CIR-1: 0.8450\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0917 Acc: 0.3503 CIR-1: 0.8411\n",
      "val Loss: 0.0926 Acc: 0.3799 CIR-1: 0.8389\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0936 Acc: 0.3307 CIR-1: 0.8451\n",
      "val Loss: 0.0941 Acc: 0.3647 CIR-1: 0.8176\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.3464 CIR-1: 0.8477\n",
      "val Loss: 0.0919 Acc: 0.3647 CIR-1: 0.8267\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0911 Acc: 0.3581 CIR-1: 0.8372\n",
      "val Loss: 0.0941 Acc: 0.3587 CIR-1: 0.8328\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "LR is set to 1.0000000000000002e-06\n",
      "train Loss: 0.0924 Acc: 0.3255 CIR-1: 0.8385\n",
      "val Loss: 0.0930 Acc: 0.3678 CIR-1: 0.8359\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0899 Acc: 0.3503 CIR-1: 0.8464\n",
      "val Loss: 0.0922 Acc: 0.3587 CIR-1: 0.8389\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0929 Acc: 0.3516 CIR-1: 0.8255\n",
      "val Loss: 0.0923 Acc: 0.3526 CIR-1: 0.8328\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0909 Acc: 0.3464 CIR-1: 0.8398\n",
      "val Loss: 0.0932 Acc: 0.3587 CIR-1: 0.8541\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.3268 CIR-1: 0.8255\n",
      "val Loss: 0.0940 Acc: 0.3647 CIR-1: 0.8359\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.3594 CIR-1: 0.8464\n",
      "val Loss: 0.0936 Acc: 0.3647 CIR-1: 0.8328\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0911 Acc: 0.3451 CIR-1: 0.8438\n",
      "val Loss: 0.0928 Acc: 0.3799 CIR-1: 0.8602\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "LR is set to 1.0000000000000002e-07\n",
      "train Loss: 0.0929 Acc: 0.3268 CIR-1: 0.8372\n",
      "val Loss: 0.0922 Acc: 0.3647 CIR-1: 0.8328\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0890 Acc: 0.3503 CIR-1: 0.8503\n",
      "val Loss: 0.0924 Acc: 0.3860 CIR-1: 0.8480\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0878 Acc: 0.3698 CIR-1: 0.8555\n",
      "val Loss: 0.0926 Acc: 0.3526 CIR-1: 0.8267\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.3281 CIR-1: 0.8529\n",
      "val Loss: 0.0926 Acc: 0.3708 CIR-1: 0.8511\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0898 Acc: 0.3424 CIR-1: 0.8385\n",
      "val Loss: 0.0933 Acc: 0.3678 CIR-1: 0.8389\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.3568 CIR-1: 0.8477\n",
      "val Loss: 0.0925 Acc: 0.3587 CIR-1: 0.8298\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.3216 CIR-1: 0.8464\n",
      "val Loss: 0.0927 Acc: 0.3678 CIR-1: 0.8389\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "LR is set to 1.0000000000000004e-08\n",
      "train Loss: 0.0920 Acc: 0.3242 CIR-1: 0.8359\n",
      "val Loss: 0.0921 Acc: 0.3556 CIR-1: 0.8389\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0890 Acc: 0.3607 CIR-1: 0.8372\n",
      "val Loss: 0.0924 Acc: 0.3739 CIR-1: 0.8419\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0934 Acc: 0.3281 CIR-1: 0.8255\n",
      "val Loss: 0.0925 Acc: 0.3556 CIR-1: 0.8237\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0904 Acc: 0.3151 CIR-1: 0.8503\n",
      "val Loss: 0.0920 Acc: 0.3617 CIR-1: 0.8328\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0900 Acc: 0.3490 CIR-1: 0.8464\n",
      "val Loss: 0.0928 Acc: 0.3951 CIR-1: 0.8389\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0938 Acc: 0.3242 CIR-1: 0.8385\n",
      "val Loss: 0.0925 Acc: 0.3830 CIR-1: 0.8389\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0888 Acc: 0.3477 CIR-1: 0.8568\n",
      "val Loss: 0.0937 Acc: 0.3617 CIR-1: 0.8298\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "LR is set to 1.0000000000000005e-09\n",
      "train Loss: 0.0905 Acc: 0.3477 CIR-1: 0.8542\n",
      "val Loss: 0.0926 Acc: 0.3678 CIR-1: 0.8389\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0893 Acc: 0.3451 CIR-1: 0.8503\n",
      "val Loss: 0.0940 Acc: 0.3495 CIR-1: 0.8237\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0957 Acc: 0.3307 CIR-1: 0.8086\n",
      "val Loss: 0.0923 Acc: 0.3647 CIR-1: 0.8328\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0932 Acc: 0.3216 CIR-1: 0.8398\n",
      "val Loss: 0.0947 Acc: 0.3647 CIR-1: 0.8176\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.3438 CIR-1: 0.8255\n",
      "val Loss: 0.0918 Acc: 0.3617 CIR-1: 0.8480\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.3581 CIR-1: 0.8490\n",
      "val Loss: 0.0920 Acc: 0.3617 CIR-1: 0.8298\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0907 Acc: 0.3672 CIR-1: 0.8542\n",
      "val Loss: 0.0918 Acc: 0.3739 CIR-1: 0.8298\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "LR is set to 1.0000000000000004e-10\n",
      "train Loss: 0.0923 Acc: 0.3503 CIR-1: 0.8477\n",
      "val Loss: 0.0930 Acc: 0.3891 CIR-1: 0.8419\n",
      "\n",
      "Training complete in 11m 37s\n",
      "Best val Acc: 0.395137\n"
>>>>>>> 7bc07c3e444b6249af57f138626e96d4fa2e9284
     ]
    }
   ],
   "source": [
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
<<<<<<< HEAD
    "\n",
    "writer = SummaryWriter('runs/resnet18_real_'+datetime.now().strftime('%B%d  %H:%M:%S'))\n",
    "model_ft = ft.train_model(model_ft, criterion, optimizer_ft,dset_loaders,dset_sizes,writer,\n",
    "                        use_gpu=use_gpu,num_epochs=100,batch_size=32,num_log=1000,init_lr=0.001,\n",
    "                         lr_scheduler=ft.exp_lr_scheduler)\n",
    "\n",
    "#model_ft = ft.train_model(model_ft, criterion, optimizer_ft,dset_loaders,dset_sizes,writer,\n",
    "#                        use_gpu=use_gpu,num_epochs=100,batch_size=32,num_log=1000,init_lr=0.001)"
=======
    "writer = SummaryWriter('runs/'+datetime.now().strftime('%B%d  %H:%M:%S'))\n",
    "model_ft = ft.train_model(model_ft, criterion, optimizer_ft, ft.exp_lr_scheduler,dset_loaders,dset_sizes,writer,\n",
    "                        use_gpu=use_gpu,num_epochs=50,batch_size=32,num_log=200)"
>>>>>>> 7bc07c3e444b6249af57f138626e96d4fa2e9284
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_ft,'./saved_models/resnet18_multi_88_real_7_15_17.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_ft=torch.load('./saved_models/resnet18_multi_88_real_7_15_17.mdl')\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_ft=torch.load('./saved_models/resnet_synthetic_7_8_17.mdl')\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# --- to-be-optimized ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the input in training is (768, 512)\n",
      "Size of the labels in training is (768,)\n",
      "Size of the input in validation is (320, 512)\n",
      "Size of the labels in validation is (320,)\n"
     ]
    }
   ],
   "source": [
    "#print(next(iter(dset_loaders['train']))[0])\n",
    "#model_ft = models.alexnet(pretrained=True)\n",
    "\n",
    "model_ft=model_ft.cpu()\n",
    "#new_classifier = nn.Sequential(*list(model_ft.classifier.children())[:-5])\n",
    "#model_ft.classifier = new_classifier\n",
    "#print(model_ft)\n",
    "model_params= list(model_ft.children())\n",
    "#model_params[1]=list(model_params[1])\n",
    "#print(model_params)\n",
    "new_ft = nn.Sequential(*list(model_params)[:-1])\n",
    "#print(new_ft)\n",
    "\n",
    "fvec_tr=np.zeros((20000,512))\n",
    "label_tr=np.zeros((20000))\n",
    "\n",
    "fvec_val=np.zeros((20000,512))\n",
    "label_val=np.zeros((20000))\n",
    "count=0;\n",
    "\n",
    "#inputs_t, classes_t = data=next(iter(dset_loaders['train']))\n",
    "#print(inputs_t.size())\n",
    "#fvec_t=new_ft(Variable(inputs_t))\n",
    "\n",
    "batch_size=32\n",
    "for data in dset_loaders['train']:\n",
    "    inputs_t, classes_t = data\n",
    "    fvec_t=new_ft(Variable(inputs_t))\n",
    "    #print(fvec_t)\n",
    "    fvec_t_cpu=fvec_t.cpu()\n",
    "    if(fvec_t_cpu.data.numpy().shape[0]==batch_size):\n",
    "        fvec_tr[count:count+batch_size,:]=fvec_t_cpu.data.numpy().reshape(batch_size,-1)\n",
    "        label_tr[count:count+batch_size]=classes_t.short().numpy()\n",
    "        count +=batch_size\n",
    "fvec_tr=fvec_tr[:count,:]\n",
    "label_tr=label_tr[:count]\n",
    "\n",
    "\n",
    "count=0;\n",
    "for data in dset_loaders['val']:\n",
    "    inputs_t, classes_t = data\n",
    "    fvec_t=new_ft(Variable(inputs_t))\n",
    "    fvec_t_cpu=fvec_t.cpu()\n",
    "    if(fvec_t_cpu.data.numpy().shape[0]==batch_size):\n",
    "        fvec_val[count:count+batch_size,:]=fvec_t_cpu.data.numpy().reshape(batch_size,-1)\n",
    "        label_val[count:count+batch_size]=classes_t.short().numpy()\n",
    "        count +=batch_size\n",
    "    \n",
    "fvec_val=fvec_val[:count,:]\n",
    "label_val=label_val[:count]\n",
    "\n",
    "'''\n",
    "print('The CNN model is')\n",
    "print(model_ft)\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "setattr(model_ft.classifier, '6', nn.Linear(num_ftrs, 9))\n",
    "#model_ft.classifier['6'] = nn.Linear(num_ftrs, 2)\n",
    "print(model_ft)\n",
    "'''\n",
    "\n",
    "print('Size of the input in training is '+str(fvec_tr.shape))\n",
    "print('Size of the labels in training is '+str(label_tr.shape))\n",
    "\n",
    "print('Size of the input in validation is '+str(fvec_val.shape))\n",
    "print('Size of the labels in validation is '+str(label_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(fvec_val.shape)\n",
    "print(fvec_val[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "#clf = SVC(C=1,kernel='linear',class_weight='balanced',decision_function_shape='ovo')\n",
    "clf=OneVsOneClassifier(LinearSVC(C=1))\n",
    "clf.fit(fvec_tr,label_tr)\n",
    "label_pred=clf.predict(fvec_val)\n",
    "abs_err=np.abs(label_pred-label_val)\n",
    "cir1=np.mean(abs_err<=1)\n",
    "print(cir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1.0 , g =  0.00390625 , cir-1 = 0.534375\n",
      "C = 1.0 , g =  0.0078125 , cir-1 = 0.525\n",
      "C = 1.0 , g =  0.015625 , cir-1 = 0.53125\n",
      "C = 1.0 , g =  0.03125 , cir-1 = 0.4375\n",
      "C = 1.0 , g =  0.0625 , cir-1 = 0.4375\n",
      "C = 1.0 , g =  0.125 , cir-1 = 0.4375\n",
      "C = 1.0 , g =  0.25 , cir-1 = 0.4375\n",
      "C = 1.0 , g =  0.5 , cir-1 = 0.4375\n",
      "C = 2.0 , g =  0.00390625 , cir-1 = 0.54375\n",
      "C = 2.0 , g =  0.0078125 , cir-1 = 0.540625\n",
      "C = 2.0 , g =  0.015625 , cir-1 = 0.534375\n",
      "C = 2.0 , g =  0.03125 , cir-1 = 0.4375\n",
      "C = 2.0 , g =  0.0625 , cir-1 = 0.4375\n",
      "C = 2.0 , g =  0.125 , cir-1 = 0.4375\n",
      "C = 2.0 , g =  0.25 , cir-1 = 0.4375\n",
      "C = 2.0 , g =  0.5 , cir-1 = 0.4375\n",
      "C = 4.0 , g =  0.00390625 , cir-1 = 0.5375\n",
      "C = 4.0 , g =  0.0078125 , cir-1 = 0.540625\n",
      "C = 4.0 , g =  0.015625 , cir-1 = 0.534375\n",
      "C = 4.0 , g =  0.03125 , cir-1 = 0.4375\n",
      "C = 4.0 , g =  0.0625 , cir-1 = 0.4375\n",
      "C = 4.0 , g =  0.125 , cir-1 = 0.4375\n",
      "C = 4.0 , g =  0.25 , cir-1 = 0.4375\n",
      "C = 4.0 , g =  0.5 , cir-1 = 0.4375\n",
      "C = 8.0 , g =  0.00390625 , cir-1 = 0.5375\n",
      "C = 8.0 , g =  0.0078125 , cir-1 = 0.540625\n",
      "C = 8.0 , g =  0.015625 , cir-1 = 0.534375\n",
      "C = 8.0 , g =  0.03125 , cir-1 = 0.4375\n",
      "C = 8.0 , g =  0.0625 , cir-1 = 0.4375\n",
      "C = 8.0 , g =  0.125 , cir-1 = 0.4375\n",
      "C = 8.0 , g =  0.25 , cir-1 = 0.4375\n",
      "C = 8.0 , g =  0.5 , cir-1 = 0.4375\n",
      "C = 16.0 , g =  0.00390625 , cir-1 = 0.5375\n",
      "C = 16.0 , g =  0.0078125 , cir-1 = 0.540625\n",
      "C = 16.0 , g =  0.015625 , cir-1 = 0.534375\n",
      "C = 16.0 , g =  0.03125 , cir-1 = 0.4375\n",
      "C = 16.0 , g =  0.0625 , cir-1 = 0.4375\n",
      "C = 16.0 , g =  0.125 , cir-1 = 0.4375\n",
      "C = 16.0 , g =  0.25 , cir-1 = 0.4375\n",
      "C = 16.0 , g =  0.5 , cir-1 = 0.4375\n",
      "C = 32.0 , g =  0.00390625 , cir-1 = 0.5375\n",
      "C = 32.0 , g =  0.0078125 , cir-1 = 0.540625\n",
      "C = 32.0 , g =  0.015625 , cir-1 = 0.534375\n",
      "C = 32.0 , g =  0.03125 , cir-1 = 0.4375\n",
      "C = 32.0 , g =  0.0625 , cir-1 = 0.4375\n",
      "C = 32.0 , g =  0.125 , cir-1 = 0.4375\n",
      "C = 32.0 , g =  0.25 , cir-1 = 0.4375\n",
      "C = 32.0 , g =  0.5 , cir-1 = 0.4375\n",
      "C = 64.0 , g =  0.00390625 , cir-1 = 0.5375\n",
      "C = 64.0 , g =  0.0078125 , cir-1 = 0.540625\n",
      "C = 64.0 , g =  0.015625 , cir-1 = 0.534375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0bd920c68702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOneVsOneClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_svc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(label_tr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfvec_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabel_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfvec_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_ovo_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             for i in range(n_classes) for j in range(i + 1, n_classes)))))\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimators_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_ovo_binary\u001b[0;34m(estimator, X, y, i, j)\u001b[0m\n\u001b[1;32m    417\u001b[0m     return _fit_binary(estimator,\n\u001b[1;32m    418\u001b[0m                        \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                        y_binary, classes=[i, j]), indcond\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mtezcan/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "c_val=np.power(2,np.arange(0.,8.,1.))\n",
    "g_val=np.power(2,np.arange(-8.,0.,1.))\n",
    "\n",
    "#c_val=[1e-10]\n",
    "#g_val=[np.power(2,-7.)]\n",
    "cir1_max=0.\n",
    "c_max=0\n",
    "g_max=0\n",
    "for c_1 in c_val:\n",
    "    for g in g_val:\n",
    "        \n",
    "        clf_svc = SVC(C=c_1,kernel='rbf',gamma=g,shrinking=False,class_weight='balanced')\n",
    "        clf=OneVsOneClassifier(clf_svc)\n",
    "        #print(label_tr)\n",
    "        clf.fit(fvec_tr,label_tr)\n",
    "\n",
    "        label_pred=clf.predict(fvec_val)\n",
    "        #print(label_pred)\n",
    "        abs_err=np.abs(label_pred-label_val)\n",
    "        #print(abs_err)\n",
    "        cir1=np.mean(abs_err<=1)\n",
    "        print('C = '+str(c_1),', g = ',str(g),', cir-1 = '+str(cir1))\n",
    "        if(cir1>cir1_max):\n",
    "            cir1_max=cir1\n",
    "            c_max=c_1\n",
    "            g_max=g\n",
    "            \n",
    "\n",
    "clf = SVC(C=c_max,kernel='linear',gamma=g_max)#,class_weight='balanced')\n",
    "clf.fit(fvec_tr,label_tr)\n",
    "label_pred=clf.predict(fvec_val)\n",
    "abs_err=np.abs(label_pred-label_val)\n",
    "print('Max CIR-1 achieved is '+str(np.mean(abs_err<=1)) +' with c='+str(c_max),', g='+str(g_max))\n",
    "print('CIR-0 = '+str(np.mean(abs_err<=0)))\n",
    "print('CIR-2 = '+str(np.mean(abs_err<=2)))\n",
    "print(abs_err)\n",
    "print(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "#print('The CNN model is')\n",
    "#print(model_ft)\n",
    "#print(list(model_ft.children())[:-1])\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "#setattr(model_ft.classifier, '6', nn.Linear(num_ftrs, 9))\n",
    "model_ft.fc = nn.Linear(num_ftrs, 9)\n",
    "#print(model_ft)\n",
    "\n",
    "#print(next(iter(dset_loaders['train']))[0])\n",
    "new_ft = nn.Sequential(*list(model_ft.children())[:-1])\n",
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=4,\n",
    "                                               shuffle=True, num_workers=4)\n",
    "                for x in ['train', 'val']}\n",
    "\n",
    "fvec_tr=np.zeros((X_tr.shape[0],512))\n",
    "for k in range(0,10,10):#(0,inputs.shape[0],10):\n",
    "    print(k)\n",
    "    fvec_now=new_ft(Variable(torch.from_numpy(X_tr[k:k+10,:,:,:])))\n",
    "    print(fvec_now.numpy())\n",
    "\n",
    "print(fvec)\n",
    "\n",
    "\n",
    "'''\n",
    "print('The CNN model is')\n",
    "print(model_ft)\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "setattr(model_ft.classifier, '6', nn.Linear(num_ftrs, 9))\n",
    "#model_ft.classifier['6'] = nn.Linear(num_ftrs, 2)\n",
    "print(model_ft)\n",
    "'''\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
    "minute.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet as fixed feature extractor\n",
    "----------------------------------\n",
    "\n",
    "Here, we need to freeze all the network except the final layer. We need\n",
    "to set ``requires_grad == False`` to freeze the parameters so that the\n",
    "gradients are not computed in ``backward()``.\n",
    "\n",
    "You can read more about this in the documentation\n",
    "`here <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    #print(param)\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model_conv.fc.parameters():\n",
    "    #print(param)\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 9)\n",
    "\n",
    "if use_gpu:\n",
    "    model_conv = model_conv.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opoosed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "On CPU this will take about half the time compared to previous scenario.\n",
    "This is expected as gradients don't need to be computed for most of the\n",
    "network. However, forward does need to be computed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
