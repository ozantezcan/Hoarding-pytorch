{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtezcan/anaconda3/lib/python3.6/site-packages/torchsample-0.1.2-py3.6.egg/torchsample/datasets.py:16: UserWarning: Cant import nibabel.. Cant load brain images\n"
     ]
    }
   ],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchsample\n",
    "from torchsample import transforms as ts_transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from torchsample.transforms import RangeNorm\n",
    "\n",
    "import functions.fine_tune as ft\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768\n",
      "329\n",
      "329\n",
      "['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training \n",
    "# Just normalization for validation\n",
    "dataset_both=False\n",
    "dataset='real'\n",
    "uniform_sampler=True\n",
    "batch_size=16\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        #ts_transforms.RandomRotate(30)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "if(dataset=='real'):\n",
    "    data_dir = '..//Data_Sets//pruned//good'\n",
    "    dsets = {x: datasets.ImageFolder_mtezcan([os.path.join(data_dir, x)], data_transforms[x])\n",
    "             for x in ['train', 'val']}\n",
    "    dsets_real = dsets\n",
    "    \n",
    "if(dataset=='mit_indoor'):\n",
    "    data_dir = '..//Data_Sets//MIT_indoor_scenes'\n",
    "    dsets = {x: datasets.ImageFolder_mtezcan([os.path.join(data_dir, x)], data_transforms[x])\n",
    "             for x in ['train', 'val']}\n",
    "    dsets_real = dsets\n",
    "    \n",
    "if(dataset=='synthetic'):\n",
    "    rootdir='//media//mtezcan//New Volume/HoardingImages//_rated//'\n",
    "    valdir='//media//mtezcan//New Volume/HoardingImages//_val//validation//House//'\n",
    "    #subdirs=os.listdir(rootdir)\n",
    "    subdirs = ['BasicHouse_2017-07-01-rated',\n",
    "               'BriansHouse_2017-06-30-rated',\n",
    "               'RuralHome_2017-06-30-rated',\n",
    "               'SmallApt_2017-06-29-rated']\n",
    "    roomdirs=['//BR','//Kitchen','//LR']\n",
    "    '''\n",
    "    rootdir='//media//mtezcan//New Volume/HoardingImages//_rated//train//'\n",
    "    valdir='//media//mtezcan//New Volume/HoardingImages//_rated//val//BriansHouse_2017-06-30-rated//LR//'\n",
    "    subdirs=['BriansHouse_2017-06-30-rated']\n",
    "    print(subdirs)\n",
    "    roomdirs=['//LR']\n",
    "    '''\n",
    "    dsets = {'train':datasets.ImageFolder_mtezcan([rootdir+subdir+room for subdir in subdirs\n",
    "                                                   for room in roomdirs], data_transforms['train']),\n",
    "             'val':datasets.ImageFolder_mtezcan([valdir+room for room in roomdirs], data_transforms['val'])}\n",
    " \n",
    "if(uniform_sampler):\n",
    "    weights,wpc = ft.make_weights_for_balanced_classes(dsets['train'].imgs, len(dsets['train'].classes))  \n",
    "    weights = torch.DoubleTensor(weights) \n",
    "    sampler = {'train':torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)) ,\n",
    "               'val':None}\n",
    "else:\n",
    "    sampler = {'train':None,\n",
    "               'val':None}\n",
    "\n",
    "shuffler={'train':True,'val':False}\n",
    "dset_loaders = {x:torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,shuffle=shuffler[x],sampler=sampler[x], num_workers=12)\n",
    "                for x in ['train','val']}\n",
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
    "dset_classes = dsets['train'].classes\n",
    "print(dset_classes)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if(dataset=='real'):\n",
    "    dset_loaders_real=dset_loaders\n",
    "    dset_sizes_real=dset_sizes\n",
    "elif(dataset=='synthetic'):\n",
    "    dset_loaders_synthetic=dset_loaders\n",
    "    dset_sizes_synthetic=dset_sizes\n",
    "#use_gpu=False\n",
    "if use_gpu:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('!!!!! NO CUDA GPUS DETECTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "inputs, classes = next(iter(dset_loaders['train']))\n",
    "#print(classes.cpu().numpy().reshape(4,4)+1)\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs,nrow=4)\n",
    "print('Size of the input tensors in one batch after grid is  '+str(out.size()))\n",
    "plt.figure(figsize=(12,12))\n",
    "ft.imshow(out, title=[dset_classes[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the convnet\n",
    "----------------------\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeLog(logname):\n",
    "    f=open('runs/'+logname+'/Network_properties.txt','w')\n",
    "    if(dataset_both):\n",
    "        f.write('Dataset: both\\n')\n",
    "    else:\n",
    "        f.write('Dataset: '+dataset+'\\n')\n",
    "    f.write('Batch size: '+str(batch_size)+'\\n')\n",
    "    f.write('Network: '+network+'\\n')\n",
    "    f.write('Uniform sampler: '+str(uniform_sampler)+'\\n')\n",
    "    f.write('Criterion: '+criteria+'\\n')\n",
    "    f.write('Learning rate: '+str(lr)+'\\n')\n",
    "    f.write('Momentum: '+str(momentum)+'\\n')\n",
    "    f.write('Leraning Rate Scheduler: '+str(lr_scheduler)+'\\n')\n",
    "    f.write('Leraning Rate Decay Period: '+str(lr_decay_epoch)+'\\n')\n",
    "    f.write('Network is pretrained: '+str(pretrained)+'\\n')\n",
    "    f.write('Network laoded from: '+networkName+'\\n')\n",
    "    f.write('MSE loss function: '+str(mse_loss)+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import time\n",
    "\n",
    "\n",
    "'''iter_loc=12\n",
    "book = openpyxl.load_workbook('logs.xlsx')\n",
    "sheet = book.active\n",
    "sheet.append((1,2,3,4,5,6,7,8,9))\n",
    "n=sheet.max_row\n",
    "sheet.cell(row=n,column=7).value=123\n",
    "\n",
    "book.save('logs.xlsx')'''\n",
    "\n",
    "def writeLog_xlsx(logname='logs.xlsx',iter_loc=13):\n",
    "    book = openpyxl.load_workbook(logname)\n",
    "    sheet = book.active\n",
    "    if network=='loaded':\n",
    "        specs=(datetime.now().strftime('%B%d  %H:%M:%S'),networkName,dataset, optimizer, str(uniform_sampler),\n",
    "          criteria,str(lr),str(momentum),str(lr_scheduler),str(lr_decay_epoch),str(pretrained),\n",
    "           str(batch_size))\n",
    "    else:\n",
    "        specs=(datetime.now().strftime('%B%d  %H:%M:%S'),network,dataset, optimizer, str(uniform_sampler),\n",
    "          criteria,str(lr),str(momentum),str(lr_scheduler),str(lr_decay_epoch),str(pretrained),\n",
    "           str(batch_size))\n",
    "    sheet.append(specs)\n",
    "    current_row = sheet.max_row\n",
    "    sheet.cell(row=current_row, column=iter_loc+5).value = comment\n",
    "    #n=sheet.max_row\n",
    "    #sheet.cell(row=n,column=7).value=123\n",
    "    book.save(logname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment=' ' #'Tested for three rooms'\n",
    "network='loaded'\n",
    "networkName='loaded_synthetic_sgd_multisoft_August29  11:48:59'\n",
    "optimizer='sgd'\n",
    "criteria='multisoft'\n",
    "iter_loc=13\n",
    "end_to_end=True\n",
    "lr=0.01\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "lr_scheduler=ft.exp_lr_scheduler\n",
    "lr_decay_epoch=10\n",
    "pretrained=True\n",
    "mse_loss=False\n",
    "if(dataset=='mit_indoor'):\n",
    "    nclasses=67\n",
    "else:\n",
    "    nclasses=9\n",
    "if(criteria=='crossentropy'):\n",
    "    multilabel=False\n",
    "else:\n",
    "    multilabel=True\n",
    "\n",
    "if(network=='resnet18'):\n",
    "    model_ft = models.resnet18(pretrained=pretrained)\n",
    "    if not end_to_end:\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False \n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    if(mse_loss):\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "    else:    \n",
    "        model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "elif(network=='resnet50'):\n",
    "    model_ft = models.resnet50(pretrained=pretrained)\n",
    "    if not end_to_end:\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False \n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    if(mse_loss):\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "    else:    \n",
    "        model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "elif(network=='resnet101'):\n",
    "    model_ft = models.resnet101(pretrained=pretrained)\n",
    "    if not end_to_end:\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False \n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    if(mse_loss):\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "    else:    \n",
    "        model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "elif(network=='alexnet'):\n",
    "    model_ft = models.alexnet(pretrained=pretrained)\n",
    "    num_ftrs = model_ft.classifier[6].out_features\n",
    "    setattr(model_ft.classifier, '7', nn.ReLU(inplace=True))\n",
    "    setattr(model_ft.classifier, '8', nn.Dropout())\n",
    "    setattr(model_ft.classifier, '9', nn.Linear(num_ftrs,nclasses))\n",
    "elif(network=='loaded'):\n",
    "    model_ft = torch.load('./saved_models/'+networkName)\n",
    "    if not end_to_end:\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False \n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, nclasses)\n",
    "else:\n",
    "    raise ValueError('Undefined network '+network)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "if(criteria=='crossentropy'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "elif(criteria=='multisoft'):\n",
    "    criterion=nn.MultiLabelSoftMarginLoss()\n",
    "else:\n",
    "    raise ValueError('Undefined criteria '+criteria)\n",
    "    \n",
    "if(optimizer=='adam'):\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "elif(optimizer=='sgd'):\n",
    "    if(end_to_end):\n",
    "        optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)#,weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer_ft = optim.SGD(model_ft.fc.parameters(), lr=lr, momentum=momentum,weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "LR is set to 0.01\n",
      "1/2, Loss: 0.0408 Acc: 0.1500 CIR-1: 0.3937\n",
      "2/2, Loss: 0.0362 Acc: 0.1437 CIR-1: 0.4938\n",
      "Val Loss: 0.0366 Acc: 0.1854 CIR-1: 0.5167\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "1/2, Loss: 0.0352 Acc: 0.1938 CIR-1: 0.5687\n",
      "2/2, Loss: 0.0330 Acc: 0.2250 CIR-1: 0.6562\n",
      "Val Loss: 0.0323 Acc: 0.2614 CIR-1: 0.6717\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "1/2, Loss: 0.0322 Acc: 0.2125 CIR-1: 0.6062\n",
      "2/2, Loss: 0.0306 Acc: 0.2188 CIR-1: 0.6813\n",
      "Val Loss: 0.0309 Acc: 0.2584 CIR-1: 0.6748\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "1/2, Loss: 0.0306 Acc: 0.2188 CIR-1: 0.6562\n",
      "2/2, Loss: 0.0299 Acc: 0.2188 CIR-1: 0.6937\n",
      "Val Loss: 0.0299 Acc: 0.2736 CIR-1: 0.6869\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "1/2, Loss: 0.0296 Acc: 0.2437 CIR-1: 0.6562\n",
      "2/2, Loss: 0.0283 Acc: 0.2313 CIR-1: 0.7125\n",
      "Val Loss: 0.0290 Acc: 0.2857 CIR-1: 0.7082\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "1/2, Loss: 0.0277 Acc: 0.2250 CIR-1: 0.7312\n",
      "2/2, Loss: 0.0252 Acc: 0.2625 CIR-1: 0.7688\n",
      "Val Loss: 0.0282 Acc: 0.2796 CIR-1: 0.7112\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "1/2, Loss: 0.0269 Acc: 0.2938 CIR-1: 0.7438\n",
      "2/2, Loss: 0.0295 Acc: 0.2625 CIR-1: 0.6188\n",
      "Val Loss: 0.0282 Acc: 0.2857 CIR-1: 0.6839\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "1/2, Loss: 0.0250 Acc: 0.2625 CIR-1: 0.7875\n",
      "2/2, Loss: 0.0259 Acc: 0.2625 CIR-1: 0.7688\n",
      "Val Loss: 0.0272 Acc: 0.3131 CIR-1: 0.7386\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "1/2, Loss: 0.0248 Acc: 0.2437 CIR-1: 0.7750\n",
      "2/2, Loss: 0.0238 Acc: 0.2938 CIR-1: 0.7875\n",
      "Val Loss: 0.0266 Acc: 0.2979 CIR-1: 0.7356\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "1/2, Loss: 0.0223 Acc: 0.3250 CIR-1: 0.8187\n",
      "2/2, Loss: 0.0246 Acc: 0.2188 CIR-1: 0.8000\n",
      "Val Loss: 0.0262 Acc: 0.3222 CIR-1: 0.7386\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "LR is set to 0.001\n",
      "1/2, Loss: 0.0268 Acc: 0.2562 CIR-1: 0.7500\n",
      "2/2, Loss: 0.0234 Acc: 0.2313 CIR-1: 0.7875\n",
      "Val Loss: 0.0261 Acc: 0.3222 CIR-1: 0.7568\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "1/2, Loss: 0.0240 Acc: 0.3000 CIR-1: 0.8250\n",
      "2/2, Loss: 0.0245 Acc: 0.2875 CIR-1: 0.7750\n",
      "Val Loss: 0.0261 Acc: 0.3191 CIR-1: 0.7477\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "1/2, Loss: 0.0241 Acc: 0.3625 CIR-1: 0.8000\n",
      "2/2, Loss: 0.0261 Acc: 0.2313 CIR-1: 0.7562\n",
      "Val Loss: 0.0259 Acc: 0.3191 CIR-1: 0.7568\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "1/2, Loss: 0.0249 Acc: 0.3187 CIR-1: 0.7688\n",
      "2/2, Loss: 0.0223 Acc: 0.2875 CIR-1: 0.8187\n",
      "Val Loss: 0.0260 Acc: 0.3252 CIR-1: 0.7568\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "1/2, Loss: 0.0239 Acc: 0.3125 CIR-1: 0.7625\n",
      "2/2, Loss: 0.0246 Acc: 0.2500 CIR-1: 0.7875\n",
      "Val Loss: 0.0261 Acc: 0.3252 CIR-1: 0.7568\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "1/2, Loss: 0.0231 Acc: 0.2750 CIR-1: 0.8313\n",
      "2/2, Loss: 0.0234 Acc: 0.2625 CIR-1: 0.7937\n",
      "Val Loss: 0.0259 Acc: 0.3131 CIR-1: 0.7599\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "1/2, Loss: 0.0233 Acc: 0.3187 CIR-1: 0.7812\n",
      "2/2, Loss: 0.0241 Acc: 0.3063 CIR-1: 0.7875\n",
      "Val Loss: 0.0259 Acc: 0.3131 CIR-1: 0.7629\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "1/2, Loss: 0.0212 Acc: 0.2687 CIR-1: 0.8375\n",
      "2/2, Loss: 0.0237 Acc: 0.2625 CIR-1: 0.7438\n",
      "Val Loss: 0.0260 Acc: 0.3252 CIR-1: 0.7568\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "1/2, Loss: 0.0225 Acc: 0.3125 CIR-1: 0.8125\n",
      "2/2, Loss: 0.0224 Acc: 0.2938 CIR-1: 0.8063\n",
      "Val Loss: 0.0258 Acc: 0.3161 CIR-1: 0.7690\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "1/2, Loss: 0.0235 Acc: 0.2750 CIR-1: 0.8125\n",
      "2/2, Loss: 0.0239 Acc: 0.2875 CIR-1: 0.8313\n",
      "Val Loss: 0.0257 Acc: 0.3283 CIR-1: 0.7690\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "LR is set to 0.00010000000000000002\n",
      "1/2, Loss: 0.0221 Acc: 0.3312 CIR-1: 0.8187\n",
      "2/2, Loss: 0.0264 Acc: 0.2750 CIR-1: 0.7375\n",
      "Val Loss: 0.0257 Acc: 0.3191 CIR-1: 0.7781\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "1/2, Loss: 0.0243 Acc: 0.3063 CIR-1: 0.7688\n",
      "2/2, Loss: 0.0228 Acc: 0.2625 CIR-1: 0.8313\n",
      "Val Loss: 0.0258 Acc: 0.3131 CIR-1: 0.7781\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "1/2, Loss: 0.0233 Acc: 0.2750 CIR-1: 0.7875\n",
      "2/2, Loss: 0.0218 Acc: 0.3688 CIR-1: 0.8438\n",
      "Val Loss: 0.0257 Acc: 0.3313 CIR-1: 0.7720\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "1/2, Loss: 0.0247 Acc: 0.2875 CIR-1: 0.7562\n",
      "2/2, Loss: 0.0236 Acc: 0.3063 CIR-1: 0.8000\n",
      "Val Loss: 0.0259 Acc: 0.3222 CIR-1: 0.7660\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "1/2, Loss: 0.0232 Acc: 0.2750 CIR-1: 0.7937\n",
      "2/2, Loss: 0.0231 Acc: 0.2500 CIR-1: 0.8250\n",
      "Val Loss: 0.0259 Acc: 0.3222 CIR-1: 0.7690\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "1/2, Loss: 0.0231 Acc: 0.3375 CIR-1: 0.8125\n",
      "2/2, Loss: 0.0235 Acc: 0.2750 CIR-1: 0.8313\n",
      "Val Loss: 0.0258 Acc: 0.3222 CIR-1: 0.7751\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "1/2, Loss: 0.0227 Acc: 0.2875 CIR-1: 0.8125\n",
      "2/2, Loss: 0.0234 Acc: 0.3312 CIR-1: 0.8000\n",
      "Val Loss: 0.0257 Acc: 0.3283 CIR-1: 0.7720\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "1/2, Loss: 0.0230 Acc: 0.2500 CIR-1: 0.8187\n",
      "2/2, Loss: 0.0227 Acc: 0.3063 CIR-1: 0.7812\n",
      "Val Loss: 0.0257 Acc: 0.3161 CIR-1: 0.7660\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "1/2, Loss: 0.0234 Acc: 0.2812 CIR-1: 0.7937\n",
      "2/2, Loss: 0.0242 Acc: 0.2687 CIR-1: 0.7875\n",
      "Val Loss: 0.0257 Acc: 0.3191 CIR-1: 0.7690\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "1/2, Loss: 0.0244 Acc: 0.2625 CIR-1: 0.7625\n",
      "2/2, Loss: 0.0242 Acc: 0.2437 CIR-1: 0.7688\n",
      "Val Loss: 0.0258 Acc: 0.3252 CIR-1: 0.7720\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "LR is set to 1.0000000000000003e-05\n",
      "1/2, Loss: 0.0235 Acc: 0.2875 CIR-1: 0.7937\n",
      "2/2, Loss: 0.0216 Acc: 0.3000 CIR-1: 0.8375\n",
      "Val Loss: 0.0258 Acc: 0.3343 CIR-1: 0.7660\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "1/2, Loss: 0.0240 Acc: 0.3812 CIR-1: 0.8000\n",
      "2/2, Loss: 0.0230 Acc: 0.2812 CIR-1: 0.8125\n",
      "Val Loss: 0.0259 Acc: 0.3283 CIR-1: 0.7629\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "1/2, Loss: 0.0226 Acc: 0.3187 CIR-1: 0.8313\n",
      "2/2, Loss: 0.0245 Acc: 0.3500 CIR-1: 0.7937\n",
      "Val Loss: 0.0258 Acc: 0.3313 CIR-1: 0.7690\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "1/2, Loss: 0.0239 Acc: 0.2875 CIR-1: 0.7937\n",
      "2/2, Loss: 0.0212 Acc: 0.3063 CIR-1: 0.8313\n",
      "Val Loss: 0.0257 Acc: 0.3191 CIR-1: 0.7842\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "1/2, Loss: 0.0227 Acc: 0.2938 CIR-1: 0.8125\n",
      "2/2, Loss: 0.0211 Acc: 0.3187 CIR-1: 0.8812\n",
      "Val Loss: 0.0258 Acc: 0.3070 CIR-1: 0.7781\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "1/2, Loss: 0.0209 Acc: 0.2938 CIR-1: 0.8625\n",
      "2/2, Loss: 0.0249 Acc: 0.2625 CIR-1: 0.7812\n",
      "Val Loss: 0.0257 Acc: 0.3252 CIR-1: 0.7690\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "1/2, Loss: 0.0232 Acc: 0.2687 CIR-1: 0.7937\n",
      "2/2, Loss: 0.0248 Acc: 0.3125 CIR-1: 0.8000\n",
      "Val Loss: 0.0257 Acc: 0.3131 CIR-1: 0.7720\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "1/2, Loss: 0.0224 Acc: 0.2812 CIR-1: 0.8313\n",
      "2/2, Loss: 0.0228 Acc: 0.2812 CIR-1: 0.7875\n",
      "Val Loss: 0.0258 Acc: 0.3283 CIR-1: 0.7690\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "1/2, Loss: 0.0234 Acc: 0.2250 CIR-1: 0.7750\n",
      "2/2, Loss: 0.0225 Acc: 0.2625 CIR-1: 0.8063\n",
      "Val Loss: 0.0258 Acc: 0.3252 CIR-1: 0.7690\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "1/2, Loss: 0.0210 Acc: 0.3125 CIR-1: 0.8750\n",
      "2/2, Loss: 0.0219 Acc: 0.3250 CIR-1: 0.8625\n",
      "Val Loss: 0.0257 Acc: 0.3191 CIR-1: 0.7842\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "LR is set to 1.0000000000000002e-06\n",
      "1/2, Loss: 0.0255 Acc: 0.3750 CIR-1: 0.7937\n",
      "2/2, Loss: 0.0248 Acc: 0.3000 CIR-1: 0.7500\n",
      "Val Loss: 0.0260 Acc: 0.3131 CIR-1: 0.7538\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "1/2, Loss: 0.0219 Acc: 0.3063 CIR-1: 0.8125\n",
      "2/2, Loss: 0.0239 Acc: 0.2812 CIR-1: 0.7937\n",
      "Val Loss: 0.0259 Acc: 0.3070 CIR-1: 0.7781\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "1/2, Loss: 0.0242 Acc: 0.2687 CIR-1: 0.8187\n",
      "2/2, Loss: 0.0224 Acc: 0.2500 CIR-1: 0.8313\n",
      "Val Loss: 0.0257 Acc: 0.3222 CIR-1: 0.7720\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "1/2, Loss: 0.0230 Acc: 0.3063 CIR-1: 0.7812\n",
      "2/2, Loss: 0.0216 Acc: 0.2500 CIR-1: 0.8187\n",
      "Val Loss: 0.0257 Acc: 0.3252 CIR-1: 0.7812\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "1/2, Loss: 0.0250 Acc: 0.2812 CIR-1: 0.7875\n",
      "2/2, Loss: 0.0218 Acc: 0.3187 CIR-1: 0.8250\n",
      "Val Loss: 0.0260 Acc: 0.3131 CIR-1: 0.7629\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "1/2, Loss: 0.0225 Acc: 0.3125 CIR-1: 0.8688\n",
      "2/2, Loss: 0.0236 Acc: 0.2687 CIR-1: 0.7937\n",
      "Val Loss: 0.0257 Acc: 0.3222 CIR-1: 0.7812\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "1/2, Loss: 0.0229 Acc: 0.3375 CIR-1: 0.8125\n",
      "2/2, Loss: 0.0228 Acc: 0.3000 CIR-1: 0.8000\n",
      "Val Loss: 0.0258 Acc: 0.3252 CIR-1: 0.7629\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "1/2, Loss: 0.0246 Acc: 0.2875 CIR-1: 0.7375\n",
      "2/2, Loss: 0.0228 Acc: 0.2687 CIR-1: 0.8063\n",
      "Val Loss: 0.0258 Acc: 0.3252 CIR-1: 0.7660\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "1/2, Loss: 0.0217 Acc: 0.3500 CIR-1: 0.8187\n",
      "2/2, Loss: 0.0228 Acc: 0.2500 CIR-1: 0.8063\n",
      "Val Loss: 0.0258 Acc: 0.3283 CIR-1: 0.7690\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "1/2, Loss: 0.0237 Acc: 0.2375 CIR-1: 0.7937\n",
      "2/2, Loss: 0.0240 Acc: 0.3688 CIR-1: 0.8125\n",
      "Val Loss: 0.0258 Acc: 0.3283 CIR-1: 0.7690\n",
      "\n",
      "Training complete in 39m 49s\n",
      "Best val Acc: 0.784195\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(ft)\n",
    "if(dataset_both):\n",
    "    data_name='both'\n",
    "else:\n",
    "    data_name=dataset\n",
    "    \n",
    "logname=network+'_'+data_name+'_'+optimizer+'_'+criteria+'_'+datetime.now().strftime('%B%d  %H:%M:%S')\n",
    "writer = SummaryWriter('runs/'+logname)\n",
    "writeLog(logname)\n",
    "writeLog_xlsx()\n",
    "if(dataset_both):\n",
    "    model_ft = ft.train_model_both(model_ft, criterion, optimizer_ft, lr_scheduler,dset_loaders_real,\n",
    "                         dset_sizes_real, dset_loaders_synthetic, dset_sizes_synthetic,writer,use_gpu=use_gpu,\n",
    "                            num_epochs=100,batch_size=batch_size,num_train=2,num_test=2,multilabel=multilabel,\n",
    "                              multi_prob=False,lr_decay_epoch=lr_decay_epoch,init_lr=lr,iter_loc=iter_loc)\n",
    "elif(uniform_sampler):\n",
    "    model_ft = ft.train_model_balanced(model_ft, criterion, optimizer_ft, lr_scheduler,dset_loaders,dset_sizes,writer,\n",
    "                            use_gpu=use_gpu,num_epochs=50,batch_size=batch_size,num_train=10,num_test=2,\n",
    "                                multilabel=multilabel, multi_prob=False,lr_decay_epoch=lr_decay_epoch,init_lr=lr, \n",
    "                                      iter_loc=iter_loc)\n",
    "else:\n",
    "    model_ft = ft.train_model(model_ft, criterion, optimizer_ft, lr_scheduler,dset_loaders,dset_sizes,writer,\n",
    "                        use_gpu=use_gpu,num_epochs=100,batch_size=batch_size,num_log=200,multilabel=multilabel,\n",
    "                          multi_prob=False,lr_decay_epoch=lr_decay_epoch,init_lr=lr,mse_loss=False,iter_loc=iter_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_ft,'./saved_models/'+logname)\n",
    "model_ft_backup=model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model_ft=torch.load('./Obsolete/saved_models/resnet18_multi_88_real_7_15_17.mdl')\n",
    "model_ft=torch.load('./saved_models/resnet_real_ft5s_multisoft__1300_100epoch_July19  12:22:17')\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion=nn.MultiLabelSoftMarginLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "model_ft = model_ft.cuda()\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# --- to-be-optimized ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(next(iter(dset_loaders['train']))[0])\n",
    "#model_ft = models.alexnet(pretrained=True)\n",
    "\n",
    "model_ft=model_ft.cpu()\n",
    "model_ft.train(False)\n",
    "#new_classifier = nn.Sequential(*list(model_ft.classifier.children())[:-5])\n",
    "#model_ft.classifier = new_classifier\n",
    "#print(model_ft)\n",
    "model_params= list(model_ft.children())\n",
    "#model_params[1]=list(model_params[1])\n",
    "#print(model_params)\n",
    "new_ft = nn.Sequential(*list(model_params)[:-1])\n",
    "#print(new_ft)\n",
    "\n",
    "fvec_tr=np.zeros((20000,512))\n",
    "label_tr=np.zeros((20000))\n",
    "\n",
    "fvec_val=np.zeros((20000,512))\n",
    "label_val=np.zeros((20000))\n",
    "count=0;\n",
    "\n",
    "#inputs_t, classes_t = data=next(iter(dset_loaders['train']))\n",
    "#print(inputs_t.size())\n",
    "#fvec_t=new_ft(Variable(inputs_t))\n",
    "\n",
    "for data in dset_loaders['train']:\n",
    "    inputs_t, classes_t = data\n",
    "    fvec_t=new_ft(Variable(inputs_t))\n",
    "    #print(fvec_t)\n",
    "    fvec_t_cpu=fvec_t.cpu()\n",
    "    if(fvec_t_cpu.data.numpy().shape[0]==4):\n",
    "        fvec_tr[count:count+4,:]=fvec_t_cpu.data.numpy().reshape(4,-1)\n",
    "        label_tr[count:count+4]=classes_t.short().numpy()\n",
    "        count +=4\n",
    "fvec_tr=fvec_tr[:count,:]\n",
    "label_tr=label_tr[:count]\n",
    "\n",
    "\n",
    "count=0;\n",
    "for data in dset_loaders['val']:\n",
    "    inputs_t, classes_t = data\n",
    "    fvec_t=new_ft(Variable(inputs_t))\n",
    "    fvec_t_cpu=fvec_t.cpu()\n",
    "    if(fvec_t_cpu.data.numpy().shape[0]==4):\n",
    "        fvec_val[count:count+4,:]=fvec_t_cpu.data.numpy().reshape(4,-1)\n",
    "        label_val[count:count+4]=classes_t.short().numpy()\n",
    "        count +=4\n",
    "    \n",
    "fvec_val=fvec_val[:count,:]\n",
    "label_val=label_val[:count]\n",
    "\n",
    "'''\n",
    "print('The CNN model is')\n",
    "print(model_ft)\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "setattr(model_ft.classifier, '6', nn.Linear(num_ftrs, 9))\n",
    "#model_ft.classifier['6'] = nn.Linear(num_ftrs, 2)\n",
    "print(model_ft)\n",
    "'''\n",
    "\n",
    "print('Size of the input in training is '+str(fvec_tr.shape))\n",
    "print('Size of the labels in training is '+str(label_tr.shape))\n",
    "\n",
    "print('Size of the input in validation is '+str(fvec_val.shape))\n",
    "print('Size of the labels in validation is '+str(label_val.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(fvec_val.shape)\n",
    "print(fvec_val[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "#clf = SVC(C=1,kernel='linear',class_weight='balanced',decision_function_shape='ovo')\n",
    "clf=OneVsOneClassifier(LinearSVC(C=1e-5))\n",
    "clf.fit(fvec_tr,label_tr)\n",
    "label_pred=clf.predict(fvec_val)\n",
    "abs_err=np.abs(label_pred-label_val)\n",
    "cir1=np.mean(abs_err<=1)\n",
    "print(cir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "c_val=np.power(2,np.arange(0.,8.,1.))\n",
    "g_val=np.power(2,np.arange(-10.,-5.,1.))\n",
    "\n",
    "#c_val=[128]\n",
    "#g_val=[np.power(2,-10.)]\n",
    "cir1_max=0.\n",
    "c_max=0\n",
    "g_max=0\n",
    "for c_1 in c_val:\n",
    "    for g in g_val:\n",
    "        \n",
    "        clf_svc = SVC(C=c_1,kernel='rbf',gamma=g,shrinking=False,class_weight='balanced')\n",
    "        clf=OneVsOneClassifier(clf_svc)\n",
    "        #print(label_tr)\n",
    "        clf.fit(fvec_tr,label_tr)\n",
    "\n",
    "        label_pred=clf.predict(fvec_val)\n",
    "        #print(label_pred)\n",
    "        abs_err=np.abs(label_pred-label_val)\n",
    "        #print(abs_err)\n",
    "        cir1=np.mean(abs_err<=1)\n",
    "        print('C = '+str(c_1),', g = ',str(g),', cir-1 = '+str(cir1))\n",
    "        if(cir1>cir1_max):\n",
    "            cir1_max=cir1\n",
    "            c_max=c_1\n",
    "            g_max=g\n",
    "            \n",
    "\n",
    "clf = SVC(C=c_max,kernel='rbf',gamma=g_max)#,class_weight='balanced')\n",
    "clf.fit(fvec_tr,label_tr)\n",
    "label_pred=clf.predict(fvec_val)\n",
    "abs_err=np.abs(label_pred-label_val)\n",
    "print('Max CIR-1 achieved is '+str(np.mean(abs_err<=1)) +' with c='+str(c_max),', g='+str(g_max))\n",
    "print('CIR-0 = '+str(np.mean(abs_err<=0)))\n",
    "print('CIR-2 = '+str(np.mean(abs_err<=2)))\n",
    "tr_pred=clf.predict(fvec_tr)\n",
    "abs_tr=np.abs(tr_pred-label_tr)\n",
    "print('Training CIR-1 is '+str(np.mean(abs_tr<=1)))\n",
    "#print(abs_err)\n",
    "#print(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "#print('The CNN model is')\n",
    "#print(model_ft)\n",
    "#print(list(model_ft.children())[:-1])\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "#setattr(model_ft.classifier, '6', nn.Linear(num_ftrs, 9))\n",
    "model_ft.fc = nn.Linear(num_ftrs, 9)\n",
    "#print(model_ft)\n",
    "\n",
    "#print(next(iter(dset_loaders['train']))[0])\n",
    "new_ft = nn.Sequential(*list(model_ft.children())[:-1])\n",
    "#dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=4,\n",
    "#                                               shuffle=True, num_workers=4)\n",
    "#                for x in ['train', 'val']}\n",
    "\n",
    "fvec_tr=np.zeros((X_tr.shape[0],512))\n",
    "for k in range(0,10,10):#(0,inputs.shape[0],10):\n",
    "    print(k)\n",
    "    fvec_now=new_ft(Variable(torch.from_numpy(X_tr[k:k+10,:,:,:])))\n",
    "    print(fvec_now.numpy())\n",
    "\n",
    "print(fvec)\n",
    "\n",
    "\n",
    "'''\n",
    "print('The CNN model is')\n",
    "print(model_ft)\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "print('Number of features in the fine tune layer is '+str(num_ftrs))\n",
    "setattr(model_ft.classifier, '6', nn.Linear(num_ftrs, 9))\n",
    "#model_ft.classifier['6'] = nn.Linear(num_ftrs, 2)\n",
    "print(model_ft)\n",
    "'''\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
    "minute.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet as fixed feature extractor\n",
    "----------------------------------\n",
    "\n",
    "Here, we need to freeze all the network except the final layer. We need\n",
    "to set ``requires_grad == False`` to freeze the parameters so that the\n",
    "gradients are not computed in ``backward()``.\n",
    "\n",
    "You can read more about this in the documentation\n",
    "`here <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    #print(param)\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model_conv.fc.parameters():\n",
    "    #print(param)\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 9)\n",
    "\n",
    "if use_gpu:\n",
    "    model_conv = model_conv.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opoosed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "On CPU this will take about half the time compared to previous scenario.\n",
    "This is expected as gradients don't need to be computed for most of the\n",
    "network. However, forward does need to be computed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_conv = ft.train_model(model_conv, criterion, optimizer_conv, ft.exp_lr_scheduler,dset_loaders,dset_sizes,writer,\n",
    "                        use_gpu=use_gpu,num_epochs=100,batch_size=32,num_log=1000,multilabel=False,multi_prob=False,\n",
    "                         lr_decay_epoch=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
